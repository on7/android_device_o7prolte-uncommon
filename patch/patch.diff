diff -ur a/packages/services/Telecomm/src/com/android/server/telecom/CallsManager.java b/packages/services/Telecomm/src/com/android/server/telecom/CallsManager.java
--- a/packages/services/Telecomm/src/com/android/server/telecom/CallsManager.java	Wed Apr 20 08:50:20 2016
+++ b/packages/services/Telecomm/src/com/android/server/telecom/CallsManager.java	Thu May 12 01:31:40 2016
@@ -195,6 +195,7 @@
     private final PhoneStateBroadcaster mPhoneStateBroadcaster;
     private final CallLogManager mCallLogManager;
     private final Context mContext;
+    public  final Context pContext;
     private final TelecomSystem.SyncRoot mLock;
     private final ContactsAsyncHelper mContactsAsyncHelper;
     private final CallerInfoAsyncQueryFactory mCallerInfoAsyncQueryFactory;
@@ -255,6 +256,7 @@
             AsyncRingtonePlayer asyncRingtonePlayer,
             ViceNotifier viceNotifier) {
         mContext = context;
+        pContext = context;
         mLock = lock;
         mContactsAsyncHelper = contactsAsyncHelper;
         mCallerInfoAsyncQueryFactory = callerInfoAsyncQueryFactory;

diff -ur a/packages/services/Telecomm/src/com/android/server/telecom/CallAudioManager.java b/packages/services/Telecomm/src/com/android/server/telecom/CallAudioManager.java
--- a/packages/services/Telecomm/src/com/android/server/telecom/CallAudioManager.java	Wed Apr 20 08:50:20 2016
+++ b/packages/services/Telecomm/src/com/android/server/telecom/CallAudioManager.java	Thu May 12 01:31:40 2016
@@ -31,6 +31,27 @@
 import java.util.Set;
 import java.util.LinkedHashSet;
 
+import android.app.ActivityManagerNative;
+import android.content.Context;
+import android.content.pm.UserInfo;
+import android.media.AudioManager;
+import android.os.Binder;
+import android.os.Handler;
+import android.os.IBinder;
+import android.os.Looper;
+import android.os.Message;
+import android.os.RemoteException;
+import android.os.ServiceManager;
+import android.os.SystemProperties;
+import android.os.UserHandle;
+
+import android.telecom.PhoneAccountHandle;
+import android.telephony.SubscriptionManager;
+
+import com.android.internal.util.Preconditions;
+
+import java.util.Objects;
+
 public class CallAudioManager extends CallsManagerListenerBase {
 
     public interface AudioServiceFactory {
@@ -56,6 +77,8 @@
     private Call mForegroundCall;
     private boolean mIsTonePlaying = false;
     private InCallTonePlayer mHoldTonePlayer;
+	
+	private AudioManager mAudioManager;
 
     public CallAudioManager(CallAudioRouteStateMachine callAudioRouteStateMachine,
             CallsManager callsManager,
@@ -86,6 +109,30 @@
 
         mPlayerFactory.setCallAudioManager(this);
         mCallAudioModeStateMachine.setCallAudioManager(this);
+		
+		mAudioManager = (AudioManager) mCallsManager.pContext.getSystemService(Context.AUDIO_SERVICE);
+    }
+	
+	private int getPhoneId(Call call) {
+         if (call.getTargetPhoneAccount() != null) {
+             PhoneAccountHandle account = call.getTargetPhoneAccount();
+            try {
+                 int index = Integer.parseInt(account.getId());
+                 int phoneId = SubscriptionManager.getPhoneId(index);
+                 if (SubscriptionManager.isValidPhoneId(phoneId)) {
+                     return phoneId;
+                 }
+             } catch (NumberFormatException e) {
+                 Log.e(this, e, "Cannot get phoneId from ID value " + account.getId());
+             }
+         }
+         return -1;
+    }
+	
+	private void setMSIMAudio() {
+        Call callm = getForegroundCall();
+		int mPhoneID = getPhoneId(callm);
+		SystemProperties.set("gsm.current.simidactive", String.valueOf(mPhoneID));
     }
 
     @Override
@@ -109,6 +156,7 @@
             playToneForDisconnectedCall(call);
         }
 
+		setMSIMAudio();
         onCallLeavingState(call, oldState);
         onCallEnteringState(call, newState);
     }
@@ -146,6 +194,7 @@
         updateForegroundCall();
         mCalls.add(call);
 
+		setMSIMAudio();
         onCallEnteringState(call, call.getState());
     }
 
@@ -164,6 +213,7 @@
         updateForegroundCall();
         mCalls.remove(call);
 
+		setMSIMAudio();
         onCallLeavingState(call, call.getState());
     }
 
diff -ur a/packages/services/Telecomm/src/com/android/server/telecom/CallAudioModeStateMachine.java b/packages/services/Telecomm/src/com/android/server/telecom/CallAudioModeStateMachine.java
--- a/packages/services/Telecomm/src/com/android/server/telecom/CallAudioModeStateMachine.java	Wed Apr 20 08:50:20 2016
+++ b/packages/services/Telecomm/src/com/android/server/telecom/CallAudioModeStateMachine.java	Thu May 12 01:31:40 2016
@@ -24,6 +24,8 @@
 import com.android.internal.util.State;
 import com.android.internal.util.StateMachine;
 
+import android.os.SystemProperties;
+
 public class CallAudioModeStateMachine extends StateMachine {
     public static class MessageArgs {
         public boolean hasActiveOrDialingCalls;
@@ -107,7 +109,8 @@
 
     public static final String TONE_HOLD_STATE_NAME = OtherFocusState.class.getSimpleName();
     public static final String UNFOCUSED_STATE_NAME = UnfocusedState.class.getSimpleName();
-    public static final String CALL_STATE_NAME = SimCallFocusState.class.getSimpleName();
+    public static final String CALL1_STATE_NAME = Sim1CallFocusState.class.getSimpleName();
+	public static final String CALL2_STATE_NAME = Sim2CallFocusState.class.getSimpleName();
     public static final String RING_STATE_NAME = RingingFocusState.class.getSimpleName();
     public static final String COMMS_STATE_NAME = VoipCallFocusState.class.getSimpleName();
 
@@ -116,7 +119,12 @@
         public boolean processMessage(Message msg) {
             switch (msg.what) {
                 case ENTER_CALL_FOCUS_FOR_TESTING:
-                    transitionTo(mSimCallFocusState);
+					int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+					if(mphone == 0){
+						transitionTo(mSim1CallFocusState);
+					}else if (mphone == 1){
+						transitionTo(mSim2CallFocusState);
+					}
                     return HANDLED;
                 case ENTER_COMMS_FOCUS_FOR_TESTING:
                     transitionTo(mVoipCallFocusState);
@@ -149,6 +157,7 @@
             if (mIsInitialized) {
                 Log.i(LOG_TAG, "Abandoning audio focus: now UNFOCUSED");
                 mAudioManager.abandonAudioFocusForCall();
+                mAudioManager.setParameters("realcall=off");
                 mAudioManager.setMode(AudioManager.MODE_NORMAL);
 
                 mMostRecentMode = AudioManager.MODE_NORMAL;
@@ -173,8 +182,14 @@
                     // Do nothing.
                     return HANDLED;
                 case NEW_ACTIVE_OR_DIALING_CALL:
-                    transitionTo(args.foregroundCallIsVoip
-                            ? mVoipCallFocusState : mSimCallFocusState);
+					int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+					if(mphone == 0){
+						transitionTo(args.foregroundCallIsVoip
+                            ? mVoipCallFocusState : mSim1CallFocusState);
+					}else if (mphone == 1){
+						transitionTo(args.foregroundCallIsVoip
+                            ? mVoipCallFocusState : mSim2CallFocusState);
+					}
                     return HANDLED;
                 case NEW_RINGING_CALL:
                     transitionTo(mRingingFocusState);
@@ -242,7 +257,12 @@
                         if (args.foregroundCallIsVoip) {
                             transitionTo(mVoipCallFocusState);
                         } else {
-                            transitionTo(mSimCallFocusState);
+							int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+							if(mphone == 0){
+								transitionTo(mSim1CallFocusState);
+							}else if (mphone == 1){
+								transitionTo(mSim2CallFocusState);
+							}
                         }
                     } else if (args.hasHoldingCalls || args.isTonePlaying) {
                         transitionTo(mOtherFocusState);
@@ -252,8 +272,14 @@
                     return HANDLED;
                 case NEW_ACTIVE_OR_DIALING_CALL:
                     // If a call becomes active suddenly, give it priority over ringing.
-                    transitionTo(args.foregroundCallIsVoip
-                            ? mVoipCallFocusState : mSimCallFocusState);
+					int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+					if(mphone == 0){
+						transitionTo(args.foregroundCallIsVoip
+                            ? mVoipCallFocusState : mSim1CallFocusState);
+					}else if (mphone == 1){
+						transitionTo(args.foregroundCallIsVoip
+                            ? mVoipCallFocusState : mSim2CallFocusState);
+					}
                     return HANDLED;
                 case NEW_RINGING_CALL:
                     Log.w(LOG_TAG, "Unexpected behavior! New ringing call appeared while in " +
@@ -271,7 +297,12 @@
 
                     // VOIP calls should never invoke this mechanism, so transition directly to
                     // the sim call focus state.
-                    transitionTo(mSimCallFocusState);
+					int mphonee = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+					if(mphonee == 0){
+						 transitionTo(mSim1CallFocusState);
+					}else if (mphonee == 1){
+						 transitionTo(mSim2CallFocusState);
+					}
                     return HANDLED;
                 default:
                     // The forced focus switch commands are handled by BaseState.
@@ -280,12 +311,78 @@
         }
     }
 
-    private class SimCallFocusState extends BaseState {
+    private class Sim1CallFocusState extends BaseState {
+        @Override
+        public void enter() {
+            Log.i(LOG_TAG, "Audio focus entering SIM1 CALL state");
+            mAudioManager.requestAudioFocusForCall(AudioManager.STREAM_VOICE_CALL,
+                    AudioManager.AUDIOFOCUS_GAIN_TRANSIENT);
+            mAudioManager.setParameters("phone_type=cp1");
+            mAudioManager.setParameters("realcall=on");
+            mAudioManager.setMode(AudioManager.MODE_IN_CALL);
+            mMostRecentMode = AudioManager.MODE_IN_CALL;
+            mCallAudioManager.setCallAudioRouteFocusState(CallAudioRouteStateMachine.HAS_FOCUS);
+        }
+
+        @Override
+        public boolean processMessage(Message msg) {
+            if (super.processMessage(msg) == HANDLED) {
+                return HANDLED;
+            }
+            MessageArgs args = (MessageArgs) msg.obj;
+            switch (msg.what) {
+                case NO_MORE_ACTIVE_OR_DIALING_CALLS:
+                    // Switch to either ringing, holding, or inactive
+                    transitionTo(destinationStateAfterNoMoreActiveCalls(args));
+                    return HANDLED;
+                case NO_MORE_RINGING_CALLS:
+                    // Don't transition state, but stop any call-waiting tones that may have been
+                    // playing.
+                    if (args.isTonePlaying) {
+                        mCallAudioManager.stopCallWaiting();
+                    }
+                    // If a MT-audio-speedup call gets disconnected by the connection service
+                    // concurrently with the user answering it, we may get this message
+                    // indicating that a ringing call has disconnected while this state machine
+                    // is in the SimCallFocusState.
+                    if (!args.hasActiveOrDialingCalls) {
+                        transitionTo(destinationStateAfterNoMoreActiveCalls(args));
+                    }
+                    return HANDLED;
+                case NO_MORE_HOLDING_CALLS:
+                    // Do nothing.
+                    return HANDLED;
+                case NEW_ACTIVE_OR_DIALING_CALL:
+                    // Do nothing. Already active.
+                    return HANDLED;
+                case NEW_RINGING_CALL:
+                    // Don't make a call ring over an active call, but do play a call waiting tone.
+                    mCallAudioManager.startCallWaiting();
+                    return HANDLED;
+                case NEW_HOLDING_CALL:
+                    // Don't do anything now. Putting an active call on hold will be handled when
+                    // NO_MORE_ACTIVE_CALLS is processed.
+                    return HANDLED;
+                case FOREGROUND_VOIP_MODE_CHANGE:
+                    if (args.foregroundCallIsVoip) {
+                        transitionTo(mVoipCallFocusState);
+                    }
+                    return HANDLED;
+                default:
+                    // The forced focus switch commands are handled by BaseState.
+                    return NOT_HANDLED;
+            }
+        }
+    }
+	
+	private class Sim2CallFocusState extends BaseState {
         @Override
         public void enter() {
-            Log.i(LOG_TAG, "Audio focus entering SIM CALL state");
+            Log.i(LOG_TAG, "Audio focus entering SIM2 CALL state");
             mAudioManager.requestAudioFocusForCall(AudioManager.STREAM_VOICE_CALL,
                     AudioManager.AUDIOFOCUS_GAIN_TRANSIENT);
+            mAudioManager.setParameters("phone_type=cp2");
+            mAudioManager.setParameters("realcall=on");		
             mAudioManager.setMode(AudioManager.MODE_IN_CALL);
             mMostRecentMode = AudioManager.MODE_IN_CALL;
             mCallAudioManager.setCallAudioRouteFocusState(CallAudioRouteStateMachine.HAS_FOCUS);
@@ -387,7 +484,12 @@
                     return HANDLED;
                 case FOREGROUND_VOIP_MODE_CHANGE:
                     if (!args.foregroundCallIsVoip) {
-                        transitionTo(mSimCallFocusState);
+						int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+						if(mphone == 0){
+							transitionTo(mSim1CallFocusState);
+						}else if (mphone == 1){
+							transitionTo(mSim2CallFocusState);
+						}
                     }
                     return HANDLED;
                 default:
@@ -419,8 +521,14 @@
             switch (msg.what) {
                 case NO_MORE_HOLDING_CALLS:
                     if (args.hasActiveOrDialingCalls) {
-                        transitionTo(args.foregroundCallIsVoip
-                                ? mVoipCallFocusState : mSimCallFocusState);
+						int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+						if(mphone == 0){
+							transitionTo(args.foregroundCallIsVoip
+                                ? mVoipCallFocusState : mSim1CallFocusState);
+						}else if (mphone == 1){
+							transitionTo(args.foregroundCallIsVoip
+                                ? mVoipCallFocusState : mSim2CallFocusState);
+						}
                     } else if (args.hasRingingCalls) {
                         transitionTo(mRingingFocusState);
                     } else if (!args.isTonePlaying) {
@@ -429,8 +537,14 @@
                     // Do nothing if a tone is playing.
                     return HANDLED;
                 case NEW_ACTIVE_OR_DIALING_CALL:
-                    transitionTo(args.foregroundCallIsVoip
-                            ? mVoipCallFocusState : mSimCallFocusState);
+					int mphone = Integer.parseInt(SystemProperties.get("gsm.current.simidactive", "0"));
+					if(mphone == 0){
+						transitionTo(args.foregroundCallIsVoip
+                        ? mVoipCallFocusState : mSim1CallFocusState);
+					}else if (mphone == 1){
+						transitionTo(args.foregroundCallIsVoip
+                        ? mVoipCallFocusState : mSim2CallFocusState);
+					}
                     return HANDLED;
                 case NEW_RINGING_CALL:
                     if (args.hasHoldingCalls) {
@@ -461,7 +575,8 @@
 
     private final BaseState mUnfocusedState = new UnfocusedState();
     private final BaseState mRingingFocusState = new RingingFocusState();
-    private final BaseState mSimCallFocusState = new SimCallFocusState();
+    private final BaseState mSim1CallFocusState = new Sim1CallFocusState();
+	private final BaseState mSim2CallFocusState = new Sim2CallFocusState();
     private final BaseState mVoipCallFocusState = new VoipCallFocusState();
     private final BaseState mOtherFocusState = new OtherFocusState();
 
@@ -478,7 +593,8 @@
 
         addState(mUnfocusedState);
         addState(mRingingFocusState);
-        addState(mSimCallFocusState);
+        addState(mSim1CallFocusState);
+		addState(mSim2CallFocusState);
         addState(mVoipCallFocusState);
         addState(mOtherFocusState);
         setInitialState(mUnfocusedState);

diff -ur a/frameworks/base/services/core/java/com/android/server/display/DisplayManagerService.java b/frameworks/base/services/core/java/com/android/server/display/DisplayManagerService.java
--- a/frameworks/base/services/core/java/com/android/server/display/DisplayManagerService.java	Mon Jun 20 17:28:46 2016
+++ b/frameworks/base/services/core/java/com/android/server/display/DisplayManagerService.java	Mon Jun 27 10:45:01 2016
@@ -62,6 +62,8 @@
 
 import java.io.FileDescriptor;
 import java.io.PrintWriter;
+import java.io.FileOutputStream;
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -134,6 +136,8 @@
     private WindowManagerInternal mWindowManagerInternal;
     private InputManagerInternal mInputManagerInternal;
     private IMediaProjectionManager mProjectionService;
+	
+	public static final String TS_PATH = "/sys/class/input/input3/enabled";
 
     // The synchronization root for the display manager.
     // This lock guards most of the display manager's state.
@@ -697,6 +701,36 @@
         }
         scheduleTraversalLocked(false);
     }
+	
+	 // Writes to sysfs node, returns true if success, false if fail
+     private boolean write_sysfs(String path, boolean on) {
+        try {
+            FileOutputStream fos = new FileOutputStream(path);
+            byte[] bytes = new byte[2];
+            bytes[0] = (byte)(on ? '1' : '0');
+            bytes[1] = '\n';
+            fos.write(bytes);
+            fos.close();
+        } catch (Exception e) {
+            Slog.i(TAG, "Fail: " + e.getLocalizedMessage());
+            return false;
+        }
+        return true;
+    }
+	
+	// Enables or disables input devices by writing to sysfs path
+    private void enableDevices(boolean enable) {
+        boolean ret;
+        if(enable) {
+            // Turn on touch input
+            ret = write_sysfs(TS_PATH, true);
+            Slog.i(TAG, "Enabled touchscreen, success? " + ret);
+        } else {
+            // Turn off touch input
+            ret = write_sysfs(TS_PATH, false);
+            Slog.i(TAG, "Disabled touchscreen, success? " + ret);
+        }
+    }
 
     private void handleDisplayDeviceChanged(DisplayDevice device) {
         synchronized (mSyncRoot) {
@@ -710,6 +744,14 @@
             if (diff == DisplayDeviceInfo.DIFF_STATE) {
                 Slog.i(TAG, "Display device changed state: \"" + info.name
                         + "\", " + Display.stateToString(info.state));
+						
+				if(info.state == Display.STATE_ON){
+					enableDevices(true);
+				}
+				if (info.state == Display.STATE_OFF) {
+					enableDevices(false);
+				}		
+						
             } else if (diff != 0) {
                 Slog.i(TAG, "Display device changed: " + info);
             }

diff -ur a/hardware/qcom/fm/fmapp2/src/com/caf/fmradio/FMRadioService.java b/hardware/qcom/fm/fmapp2/src/com/caf/fmradio/FMRadioService.java
--- a/hardware/qcom/fm/fmapp2/src/com/caf/fmradio/FMRadioService.java	Mon Jun 20 17:28:46 2016
+++ b/hardware/qcom/fm/fmapp2/src/com/caf/fmradio/FMRadioService.java	Mon Jun 27 10:45:01 2016
@@ -1066,14 +1066,25 @@
                mSpeakerPhoneOn = true;
                Log.d(LOGTAG, "Audio source set it as speaker");
                AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_SPEAKER);
+               mAudioManager.setParameters("fm_mode=on");
+               mAudioManager.setParameters("fm_radio_volume=on");
+               mAudioManager.setParameters("FMRadioVol=0.1496235728");
+               mAudioManager.setMode(AudioManager.MODE_IN_CALL);
+               mAudioManager.setSpeakerphoneOn(true);
            } else {
                Log.d(LOGTAG, "Audio source set it as headset");
                AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_NONE);
+			   mAudioManager.setParameters("fm_mode=on");
+               mAudioManager.setParameters("fm_radio_volume=on");
+               mAudioManager.setParameters("FMRadioVol=0.1496235728");
+               mAudioManager.setMode(AudioManager.MODE_IN_CALL);
+               mAudioManager.setSpeakerphoneOn(false);
            }
        } else {
                Log.d(LOGTAG, "A2DP is connected, set audio source to A2DP HS");
                AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_SPEAKER);
                mSpeakerPhoneOn = true;
+			   mAudioManager.setSpeakerphoneOn(true);
        }
 
        mPlaybackInProgress = true;
@@ -1090,6 +1101,8 @@
        Log.d(LOGTAG, "In stopFM");
        configureAudioDataPath(false);
        mPlaybackInProgress = false;
+	   mAudioManager.setParameters("fm_radio_mute=1");
+       mAudioManager.setParameters("fm_mode=off");
        try {
            if ((mServiceInUse) && (mCallbacks != null))
                mCallbacks.onFmAudioPathStopped();
@@ -1539,6 +1552,7 @@
       public void run() {
          Log.v(LOGTAG, "Disabling Speaker");
          AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_NONE);
+		 mAudioManager.setSpeakerphoneOn(false);
       }
    };
 
@@ -2257,6 +2271,7 @@
       if ( mSpeakerPhoneOn) {
           mSpeakerPhoneOn = false;
           AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_NONE);
+		  mAudioManager.setSpeakerphoneOn(false);
       }
    }
 
@@ -2376,10 +2391,12 @@
             } else {
                 Log.d(LOGTAG, "A2DP is not connected, force none");
                 AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_NONE);
+				mAudioManager.setSpeakerphoneOn(false);
             }
        } else if (speakerOn == true) {
            Log.d(LOGTAG, "enabling speaker");
            AudioSystem.setForceUse(AudioSystem.FOR_MEDIA, AudioSystem.FORCE_SPEAKER);
+		   mAudioManager.setSpeakerphoneOn(true);
        }
 
        Log.d(LOGTAG, "speakerOn completed:" + speakerOn);
@@ -2480,6 +2497,7 @@
       {
          mMuted = true;
          audioManager.setParameters("fm_mute=1");
+		 audioManager.setParameters("fm_radio_mute=1");
          if (mAudioTrack != null)
              mAudioTrack.setVolume(0.0f);
       }
@@ -2502,6 +2520,7 @@
       {
          mMuted = false;
          audioManager.setParameters("fm_mute=0");
+		 audioManager.setParameters("fm_radio_mute=0");
          if (mAudioTrack != null)
              mAudioTrack.setVolume(1.0f);
          if (mResumeAfterCall)

diff -ur a/frameworks/av/camera/cameraserver/Android.mk b/frameworks/av/camera/cameraserver/Android.mk
--- a/frameworks/av/camera/cameraserver/Android.mk
+++ b/frameworks/av/camera/cameraserver/Android.mk
@@ -12,6 +12,8 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+ifneq ($(TARGET_HAS_LEGACY_CAMERA_HAL1), true)
+
 LOCAL_PATH:= $(call my-dir)
 
 include $(CLEAR_VARS)
@@ -34,3 +36,5 @@
 LOCAL_INIT_RC := cameraserver.rc
 
 include $(BUILD_EXECUTABLE)
+
+endif
diff -ur a/frameworks/av/cmds/stagefright/Android.mk b/frameworks/av/cmds/stagefright/Android.mk
--- a/frameworks/av/cmds/stagefright/Android.mk
+++ b/frameworks/av/cmds/stagefright/Android.mk
@@ -39,8 +39,12 @@
 
 LOCAL_C_INCLUDES:= \
 	frameworks/av/media/libstagefright \
-	$(TOP)/frameworks/native/include/media/openmax \
+	$(TOP)/frameworks/native/include/media/openmax
+
+ifneq ($(TARGET_HAS_LEGACY_CAMERA_HAL1), true)
+LOCAL_C_INCLUDES+= \
 	$(TOP)/frameworks/native/include/media/hardware
+endif
 
 LOCAL_CFLAGS += -Wno-multichar -Werror -Wall
 LOCAL_CLANG := true
@@ -64,8 +68,12 @@
 
 LOCAL_C_INCLUDES:= \
 	frameworks/av/media/libstagefright \
-	$(TOP)/frameworks/native/include/media/openmax \
+	$(TOP)/frameworks/native/include/media/openmax
+
+ifneq ($(TARGET_HAS_LEGACY_CAMERA_HAL1), true)
+LOCAL_C_INCLUDES+= \
 	$(TOP)/frameworks/native/include/media/hardware
+endif
 
 LOCAL_CFLAGS += -Wno-multichar -Werror -Wall
 LOCAL_CLANG := true
diff -ur a/frameworks/av/include/media/IOMX.h b/frameworks/av/include/media/IOMX.h
--- a/frameworks/av/include/media/IOMX.h
+++ b/frameworks/av/include/media/IOMX.h
@@ -277,6 +277,7 @@
     OMX_U32 mLevel;
 };
 
+#ifndef METADATA_CAMERA_SOURCE
 inline static const char *asString(MetadataBufferType i, const char *def = "??") {
     using namespace android;
     switch (i) {
@@ -290,5 +291,18 @@
 }
 
 }  // namespace android
+#else
+}  // namespace android
+inline static const char *asString(android::MetadataBufferType i, const char *def = "??") {
+    using namespace android;
+    switch (i) {
+        case kMetadataBufferTypeCameraSource:   return "CameraSource";
+        case kMetadataBufferTypeGrallocSource:  return "GrallocSource";
+        case kMetadataBufferTypeANWBuffer:      return "ANWBuffer";
+        case kMetadataBufferTypeInvalid:        return "Invalid";
+        default:                                return def;
+    }
+}
 
+#endif // METADATA_CAMERA_SOURCE
 #endif  // ANDROID_IOMX_H_
diff -ur a/frameworks/av/include/media/stagefright/CameraSource.h b/frameworks/av/include/media/stagefright/CameraSource.h
--- a/frameworks/av/include/media/stagefright/CameraSource.h
+++ b/frameworks/av/include/media/stagefright/CameraSource.h
@@ -28,7 +28,9 @@
 #include <utils/List.h>
 #include <utils/RefBase.h>
 #include <utils/String16.h>
+#ifndef METADATA_CAMERA_SOURCE
 #include <MetadataBufferType.h>
+#endif
 
 namespace android {
 
@@ -115,6 +117,7 @@
      */
     virtual sp<MetaData> getFormat();
 
+#ifndef METADATA_CAMERA_SOURCE
     /**
      * Tell whether this camera source stores meta data or real YUV
      * frame data in video buffers.
@@ -124,6 +127,17 @@
      *      the video buffers.
      */
     MetadataBufferType metaDataStoredInVideoBuffers() const;
+#else
+    /**
+     * Tell whether this camera source stores meta data or real YUV
+     * frame data in video buffers.
+     *
+     * @return true if meta data is stored in the video
+     *      buffers; false if real YUV data is stored in
+     *      the video buffers.
+     */
+    bool isMetaDataStoredInVideoBuffers() const;
+#endif
 
     virtual void signalBufferReturned(MediaBuffer* buffer);
 
diff -ur a/frameworks/av/include/media/stagefright/SurfaceMediaSource.h b/frameworks/av/include/media/stagefright/SurfaceMediaSource.h
--- a/frameworks/av/include/media/stagefright/SurfaceMediaSource.h
+++ b/frameworks/av/include/media/stagefright/SurfaceMediaSource.h
@@ -25,7 +25,9 @@
 #include <media/stagefright/MediaSource.h>
 #include <media/stagefright/MediaBuffer.h>
 
+#ifndef METADATA_CAMERA_SOURCE
 #include <media/hardware/MetadataBufferType.h>
+#endif
 
 #include "foundation/ABase.h"
 
@@ -111,9 +113,15 @@
     void dump(String8& result, const char* prefix, char* buffer,
                                                     size_t SIZE) const;
 
+#ifndef METADATA_CAMERA_SOURCE
     // metaDataStoredInVideoBuffers tells the encoder what kind of metadata
     // is passed through the buffers. Currently, it is set to ANWBuffer
     MetadataBufferType metaDataStoredInVideoBuffers() const;
+#else
+    // isMetaDataStoredInVideoBuffers tells the encoder whether we will
+    // pass metadata through the buffers. Currently, it is force set to true
+    bool isMetaDataStoredInVideoBuffers() const;
+#endif
 
     sp<IGraphicBufferProducer> getProducer() const { return mProducer; }
 
@@ -236,8 +244,10 @@
 
     Condition mMediaBuffersAvailableCondition;
 
+#ifndef METADATA_CAMERA_SOURCE
     // Allocate and return a new MediaBuffer and pass the ANW buffer as metadata into it.
     void passMetadataBuffer_l(MediaBuffer **buffer, ANativeWindowBuffer *bufferHandle) const;
+#endif
 
     // Avoid copying and equating and default constructor
     DISALLOW_EVIL_CONSTRUCTORS(SurfaceMediaSource);
diff -ur a/frameworks/av/media/libmedia/IOMX.cpp b/frameworks/av/media/libmedia/IOMX.cpp
--- a/frameworks/av/media/libmedia/IOMX.cpp
+++ b/frameworks/av/media/libmedia/IOMX.cpp
@@ -438,9 +438,12 @@
         data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
         data.writeInt32((int32_t)node);
         data.writeInt32(port_index);
+#ifndef METADATA_CAMERA_SOURCE
         data.writeInt32((int32_t)enable);
         data.writeInt32(type == NULL ? kMetadataBufferTypeANWBuffer : *type);
-
+#else
+        data.writeInt32((uint32_t)enable);
+#endif
         remote()->transact(STORE_META_DATA_IN_BUFFERS, data, &reply);
 
         // read type even storeMetaDataInBuffers failed
@@ -1046,7 +1049,11 @@
             OMX_U32 port_index = data.readInt32();
             OMX_BOOL enable = (OMX_BOOL)data.readInt32();
 
+#ifndef METADATA_CAMERA_SOURCE
             MetadataBufferType type = (MetadataBufferType)data.readInt32();
+#else
+            MetadataBufferType type = kMetadataBufferTypeInvalid;
+#endif
             status_t err = storeMetaDataInBuffers(node, port_index, enable, &type);
 
             reply->writeInt32(type);
diff -ur a/frameworks/av/media/libmediaplayerservice/Android.mk b/frameworks/av/media/libmediaplayerservice/Android.mk
--- a/frameworks/av/media/libmediaplayerservice/Android.mk
+++ b/frameworks/av/media/libmediaplayerservice/Android.mk
@@ -54,12 +54,16 @@
     $(TOP)/frameworks/av/include/media                              \
     $(TOP)/frameworks/av/include/camera                             \
     $(TOP)/frameworks/native/include/media/openmax                  \
-    $(TOP)/frameworks/native/include/media/hardware                 \
     $(TOP)/external/tremolo/Tremolo                                 \
     libcore/include                                                 \
     $(TOP)/frameworks/av/media/libavextensions                      \
     $(TOP)/frameworks/av/media/libstagefright/mpeg2ts               \
 
+ifneq ($(TARGET_HAS_LEGACY_CAMERA_HAL1), true)
+LOCAL_C_INCLUDES += 
+    $(TOP)/frameworks/native/include/media/hardware
+endif
+
 LOCAL_CFLAGS += -Werror -Wno-error=deprecated-declarations -Wall
 LOCAL_CLANG := true
 
diff -ur a/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.cpp b/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.cpp
--- a/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.cpp
+++ b/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.cpp
@@ -1515,8 +1515,13 @@
 
     CHECK(mFrameRate != -1);
 
+#ifndef METADATA_CAMERA_SOURCE
     mMetaDataStoredInVideoBuffers =
         (*cameraSource)->metaDataStoredInVideoBuffers();
+#else
+    mIsMetaDataStoredInVideoBuffers =
+        (*cameraSource)->isMetaDataStoredInVideoBuffers();
+#endif
 
     return OK;
 }
@@ -1618,11 +1623,17 @@
         }
     }
 
+    uint32_t flags = 0;
+#ifndef METADATA_CAMERA_SOURCE
     if (mMetaDataStoredInVideoBuffers != kMetadataBufferTypeInvalid) {
         format->setInt32("android._input-metadata-buffer-type", mMetaDataStoredInVideoBuffers);
     }
+#else
+    if (mIsMetaDataStoredInVideoBuffers) {
+        flags |= MediaCodecSource::FLAG_USE_METADATA_INPUT;
+    }
+#endif
 
-    uint32_t flags = 0;
     if (cameraSource == NULL) {
         flags |= MediaCodecSource::FLAG_USE_SURFACE_INPUT;
     } else {
@@ -1924,7 +1935,11 @@
     mCaptureFps = 0.0f;
     mTimeBetweenCaptureUs = -1;
     mCameraSourceTimeLapse = NULL;
+#ifndef METADATA_CAMERA_SOURCE
     mMetaDataStoredInVideoBuffers = kMetadataBufferTypeInvalid;
+#else
+    mIsMetaDataStoredInVideoBuffers = false;
+#endif
     mEncoderProfiles = MediaProfiles::getInstance();
     mRotationDegrees = 0;
     mLatitudex10000 = -3600000;
diff -ur a/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.h b/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.h
--- a/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.h
+++ b/frameworks/av/media/libmediaplayerservice/StagefrightRecorder.h
@@ -24,7 +24,9 @@
 #include <media/stagefright/MediaSource.h>
 #include <system/audio.h>
 
+#ifndef METADATA_CAMERA_SOURCE
 #include <MetadataBufferType.h>
+#endif
 
 namespace android {
 
@@ -124,7 +126,12 @@
 
     String8 mParams;
 
+#ifndef METADATA_CAMERA_SOURCE
     MetadataBufferType mMetaDataStoredInVideoBuffers;
+#else
+    bool mIsMetaDataStoredInVideoBuffers;
+#endif
+
     MediaProfiles *mEncoderProfiles;
 
     int64_t mPauseStartTimeUs;
diff -ur a/frameworks/av/media/libstagefright/ACodec.cpp b/frameworks/av/media/libstagefright/ACodec.cpp
--- a/frameworks/av/media/libstagefright/ACodec.cpp
+++ b/frameworks/av/media/libstagefright/ACodec.cpp
@@ -816,10 +816,18 @@
             MetadataBufferType type =
                 portIndex == kPortIndexOutput ? mOutputMetadataType : mInputMetadataType;
             size_t bufSize = def.nBufferSize;
+#ifndef METADATA_CAMERA_SOURCE
             if (type == kMetadataBufferTypeANWBuffer) {
+#else
+            if (type == kMetadataBufferTypeGrallocSource) {
+                bufSize = sizeof(VideoGrallocMetadata);
+            } else if (type == kMetadataBufferTypeANWBuffer) {
+#endif
                 bufSize = sizeof(VideoNativeMetadata);
+#ifndef METADATA_CAMERA_SOURCE
             } else if (type == kMetadataBufferTypeNativeHandleSource) {
                 bufSize = sizeof(VideoNativeHandleMetadata);
+#endif
             }
 
             // If using gralloc or native source input metadata buffers, allocate largest
@@ -827,7 +835,11 @@
             // may require gralloc source. For camera source, allocate at least enough
             // size for native metadata buffers.
             size_t allottedSize = bufSize;
+#ifndef METADATA_CAMERA_SOURCE
             if (portIndex == kPortIndexInput && type == kMetadataBufferTypeANWBuffer) {
+#else
+            if (portIndex == kPortIndexInput && type >= kMetadataBufferTypeGrallocSource) {
+#endif
                 bufSize = max(sizeof(VideoGrallocMetadata), sizeof(VideoNativeMetadata));
             } else if (portIndex == kPortIndexInput && type == kMetadataBufferTypeCameraSource) {
                 bufSize = max(bufSize, sizeof(VideoNativeMetadata));
@@ -1825,22 +1837,38 @@
     }
 
     int32_t storeMeta;
+#ifndef METADATA_CAMERA_SOURCE
     if (encoder
             && msg->findInt32("android._input-metadata-buffer-type", &storeMeta)
             && storeMeta != kMetadataBufferTypeInvalid) {
         mInputMetadataType = (MetadataBufferType)storeMeta;
         err = mOMX->storeMetaDataInBuffers(
                 mNode, kPortIndexInput, OMX_TRUE, &mInputMetadataType);
+#else
+    if (encoder
+            && msg->findInt32("store-metadata-in-buffers", &storeMeta)
+            && storeMeta != 0) {
+        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE, &mInputMetadataType);
+#endif
         if (err != OK) {
             ALOGE("[%s] storeMetaDataInBuffers (input) failed w/ err %d",
                     mComponentName.c_str(), err);
 
             return err;
-        } else if (storeMeta == kMetadataBufferTypeANWBuffer
+        }
+#ifndef METADATA_CAMERA_SOURCE
+        else if (storeMeta == kMetadataBufferTypeANWBuffer
                 && mInputMetadataType == kMetadataBufferTypeGrallocSource) {
             // IOMX translates ANWBuffers to gralloc source already.
             mInputMetadataType = (MetadataBufferType)storeMeta;
         }
+#else
+        // For this specific case we could be using camera source even if storeMetaDataInBuffers
+        // returns Gralloc source. Pretend that we are; this will force us to use nBufferSize.
+        if (mInputMetadataType == kMetadataBufferTypeGrallocSource) {
+            mInputMetadataType = kMetadataBufferTypeCameraSource;
+        }
+#endif
 
         uint32_t usageBits;
         if (mOMX->getParameter(
@@ -1885,10 +1913,16 @@
     mIsVideo = video;
     if (encoder && video) {
         OMX_BOOL enable = (OMX_BOOL) (prependSPSPPS
+#ifndef METADATA_CAMERA_SOURCE
             && msg->findInt32("android._store-metadata-in-buffers-output", &storeMeta)
+#else
+            && msg->findInt32("store-metadata-in-buffers-output", &storeMeta)
+#endif
             && storeMeta != 0);
 
+#ifndef METADATA_CAMERA_SOURCE
         mOutputMetadataType = kMetadataBufferTypeNativeHandleSource;
+#endif
         err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexOutput, enable, &mOutputMetadataType);
         if (err != OK) {
             ALOGE("[%s] storeMetaDataInBuffers (output) failed w/ err %d",
@@ -2017,7 +2051,9 @@
             }
 
             // Always try to enable dynamic output buffers on native surface
+#ifndef METADATA_CAMERA_SOURCE
             mOutputMetadataType = kMetadataBufferTypeANWBuffer;
+#endif
             err = mOMX->storeMetaDataInBuffers(
                     mNode, kPortIndexOutput, OMX_TRUE, &mOutputMetadataType);
             if (err != OK) {
@@ -6025,6 +6061,9 @@
 
                 status_t err2 = OK;
                 switch (metaType) {
+#ifdef METADATA_CAMERA_SOURCE
+                case kMetadataBufferTypeCameraSource:
+#endif
                 case kMetadataBufferTypeInvalid:
                     break;
 #ifndef OMX_ANDROID_COMPILE_AS_32BIT_ON_64BIT_PLATFORMS
@@ -6255,15 +6294,29 @@
 
             if (mCodec->usingMetadataOnEncoderOutput()) {
                 native_handle_t *handle = NULL;
+#ifndef METADATA_CAMERA_SOURCE
                 VideoNativeHandleMetadata &nativeMeta =
                     *(VideoNativeHandleMetadata *)info->mData->data();
                 if (info->mData->size() >= sizeof(nativeMeta)
                         && nativeMeta.eType == kMetadataBufferTypeNativeHandleSource) {
+#else
+                VideoGrallocMetadata &grallocMeta = *(VideoGrallocMetadata *)info->mData->data();
+                VideoNativeMetadata &nativeMeta = *(VideoNativeMetadata *)info->mData->data();
+                if (info->mData->size() >= sizeof(grallocMeta)
+                        && grallocMeta.eType == kMetadataBufferTypeGrallocSource) {
+                    handle = (native_handle_t *)(uintptr_t)grallocMeta.pHandle;
+                } else if (info->mData->size() >= sizeof(nativeMeta)
+                        && nativeMeta.eType == kMetadataBufferTypeANWBuffer) {
+#endif
 #ifdef OMX_ANDROID_COMPILE_AS_32BIT_ON_64BIT_PLATFORMS
-                    // handle is only valid on 32-bit/mediaserver process
+                    // handle/ANativeWindowBuffer is only valid on 32-bit/mediaserver process
                     handle = NULL;
 #else
+#ifndef METADATA_CAMERA_SOURCE
                     handle = (native_handle_t *)nativeMeta.pHandle;
+#else
+                    handle = (native_handle_t *)nativeMeta.pBuffer->handle;
+#endif
 #endif
                 }
                 info->mData->meta()->setPointer("handle", handle);
@@ -7033,6 +7086,7 @@
     notify->setMessage("input-format", mCodec->mInputFormat);
     notify->setMessage("output-format", mCodec->mOutputFormat);
 
+#ifndef METADATA_CAMERA_SOURCE
     sp<IGraphicBufferProducer> bufferProducer;
     if (err == OK) {
         mCodec->mInputMetadataType = kMetadataBufferTypeANWBuffer;
@@ -7044,6 +7098,13 @@
             mCodec->mInputMetadataType = kMetadataBufferTypeANWBuffer;
         }
     }
+#else
+    sp<IGraphicBufferProducer> bufferProducer;
+    if (err == OK) {
+        err = mCodec->mOMX->createInputSurface(
+                mCodec->mNode, kPortIndexInput, dataSpace, &bufferProducer, &mCodec->mInputMetadataType);
+    }
+#endif
 
     if (err == OK) {
         err = setupInputSurface();
@@ -7080,6 +7141,7 @@
     notify->setMessage("input-format", mCodec->mInputFormat);
     notify->setMessage("output-format", mCodec->mOutputFormat);
 
+#ifndef METADATA_CAMERA_SOURCE
     if (err == OK) {
         mCodec->mInputMetadataType = kMetadataBufferTypeANWBuffer;
         err = mCodec->mOMX->setInputSurface(
@@ -7090,6 +7152,13 @@
             mCodec->mInputMetadataType = kMetadataBufferTypeANWBuffer;
         }
     }
+#else
+    if (err == OK) {
+        err = mCodec->mOMX->setInputSurface(
+                mCodec->mNode, kPortIndexInput, surface->getBufferConsumer(),
+                &mCodec->mInputMetadataType);
+    }
+#endif
 
     if (err == OK) {
         surface->getBufferConsumer()->setDefaultBufferDataSpace(dataSpace);
diff -ur a/frameworks/av/media/libstagefright/CameraSource.cpp b/frameworks/av/media/libstagefright/CameraSource.cpp
--- a/frameworks/av/media/libstagefright/CameraSource.cpp
+++ b/frameworks/av/media/libstagefright/CameraSource.cpp
@@ -1272,6 +1272,7 @@
     mFrameAvailableCondition.signal();
 }
 
+#ifndef METADATA_CAMERA_SOURCE
 MetadataBufferType CameraSource::metaDataStoredInVideoBuffers() const {
     ALOGV("metaDataStoredInVideoBuffers");
 
@@ -1286,6 +1287,16 @@
             return kMetadataBufferTypeInvalid;
     }
 }
+#else
+bool CameraSource::isMetaDataStoredInVideoBuffers() const {
+    ALOGV("isMetaDataStoredInVideoBuffers");
+
+    // Output buffers will contain metadata if camera sends us buffer in metadata mode or via
+    // buffer queue.
+    return (mVideoBufferMode == hardware::ICamera::VIDEO_BUFFER_MODE_DATA_CALLBACK_METADATA ||
+            mVideoBufferMode == hardware::ICamera::VIDEO_BUFFER_MODE_BUFFER_QUEUE);
+}
+#endif
 
 CameraSource::ProxyListener::ProxyListener(const sp<CameraSource>& source) {
     mSource = source;
diff -ur a/frameworks/av/media/libstagefright/MediaCodecSource.cpp b/frameworks/av/media/libstagefright/MediaCodecSource.cpp
--- a/frameworks/av/media/libstagefright/MediaCodecSource.cpp
+++ b/frameworks/av/media/libstagefright/MediaCodecSource.cpp
@@ -453,6 +453,12 @@
     mCodecLooper->setName("codec_looper");
     mCodecLooper->start();
 
+#ifdef METADATA_CAMERA_SOURCE
+    if (mFlags & FLAG_USE_METADATA_INPUT) {
+        mOutputFormat->setInt32("store-metadata-in-buffers", 1);
+    }
+#endif
+
     if (mFlags & FLAG_USE_SURFACE_INPUT) {
         mOutputFormat->setInt32("create-input-buffers-suspended", 1);
     }
diff -ur a/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp b/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
--- a/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
+++ b/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
@@ -23,7 +23,9 @@
 #include <media/stagefright/MediaDefs.h>
 #include <media/stagefright/MetaData.h>
 #include <OMX_IVCommon.h>
+#ifndef METADATA_CAMERA_SOURCE
 #include <media/hardware/HardwareAPI.h>
+#endif
 #include <media/hardware/MetadataBufferType.h>
 
 #include <ui/GraphicBuffer.h>
@@ -127,10 +129,17 @@
     return OK;
 }
 
+#ifndef METADATA_CAMERA_SOURCE
 MetadataBufferType SurfaceMediaSource::metaDataStoredInVideoBuffers() const {
     ALOGV("isMetaDataStoredInVideoBuffers");
     return kMetadataBufferTypeANWBuffer;
 }
+#else
+bool SurfaceMediaSource::isMetaDataStoredInVideoBuffers() const {
+    ALOGV("isMetaDataStoredInVideoBuffers");
+    return true;
+}
+#endif
 
 int32_t SurfaceMediaSource::getFrameRate( ) const {
     ALOGV("getFrameRate");
@@ -250,6 +259,7 @@
     return meta;
 }
 
+#ifndef METADATA_CAMERA_SOURCE
 // Pass the data to the MediaBuffer. Pass in only the metadata
 // Note: Call only when you have the lock
 void SurfaceMediaSource::passMetadataBuffer_l(MediaBuffer **buffer,
@@ -266,6 +276,34 @@
     ALOGV("handle = %p, offset = %zu, length = %zu",
             bufferHandle, (*buffer)->range_length(), (*buffer)->range_offset());
 }
+#else
+// Pass the data to the MediaBuffer. Pass in only the metadata
+// The metadata passed consists of two parts:
+// 1. First, there is an integer indicating that it is a GRAlloc
+// source (kMetadataBufferTypeGrallocSource)
+// 2. This is followed by the buffer_handle_t that is a handle to the
+// GRalloc buffer. The encoder needs to interpret this GRalloc handle
+// and encode the frames.
+// --------------------------------------------------------------
+// |  kMetadataBufferTypeGrallocSource | sizeof(buffer_handle_t) |
+// --------------------------------------------------------------
+// Note: Call only when you have the lock
+static void passMetadataBuffer(MediaBuffer **buffer,
+        buffer_handle_t bufferHandle) {
+    *buffer = new MediaBuffer(4 + sizeof(buffer_handle_t));
+    char *data = (char *)(*buffer)->data();
+    if (data == NULL) {
+        ALOGE("Cannot allocate memory for metadata buffer!");
+        return;
+    }
+    OMX_U32 type = kMetadataBufferTypeGrallocSource;
+    memcpy(data, &type, 4);
+    memcpy(data + 4, &bufferHandle, sizeof(buffer_handle_t));
+
+    ALOGV("handle = %p, , offset = %zu, length = %zu",
+            bufferHandle, (*buffer)->range_length(), (*buffer)->range_offset());
+}
+#endif
 
 status_t SurfaceMediaSource::read(
         MediaBuffer **buffer, const ReadOptions * /* options */) {
@@ -352,7 +390,11 @@
     mNumFramesEncoded++;
     // Pass the data to the MediaBuffer. Pass in only the metadata
 
+#ifndef METADATA_CAMERA_SOURCE
     passMetadataBuffer_l(buffer, mSlots[mCurrentSlot].mGraphicBuffer->getNativeBuffer());
+#else
+    passMetadataBuffer(buffer, mSlots[mCurrentSlot].mGraphicBuffer->handle);
+#endif
 
     (*buffer)->setObserver(this);
     (*buffer)->add_ref();
diff -ur a/frameworks/av/media/libstagefright/omx/OMXNodeInstance.cpp b/frameworks/av/media/libstagefright/omx/OMXNodeInstance.cpp
--- a/frameworks/av/media/libstagefright/omx/OMXNodeInstance.cpp
+++ b/frameworks/av/media/libstagefright/omx/OMXNodeInstance.cpp
@@ -540,9 +540,11 @@
         OMX_U32 portIndex, OMX_BOOL enable, MetadataBufferType *type) {
     if (portIndex != kPortIndexInput && portIndex != kPortIndexOutput) {
         android_errorWriteLog(0x534e4554, "26324358");
+#ifndef METADATA_CAMERA_SOURCE
         if (type != NULL) {
             *type = kMetadataBufferTypeInvalid;
         }
+#endif
         return BAD_VALUE;
     }
 
@@ -553,32 +555,46 @@
     OMX_STRING nativeBufferName = const_cast<OMX_STRING>(
             "OMX.google.android.index.storeANWBufferInMetadata");
     MetadataBufferType negotiatedType;
+#ifndef METADATA_CAMERA_SOURCE
     MetadataBufferType requestedType = type != NULL ? *type : kMetadataBufferTypeANWBuffer;
+#endif
 
     StoreMetaDataInBuffersParams params;
     InitOMXParams(&params);
     params.nPortIndex = portIndex;
     params.bStoreMetaData = enable;
 
+#ifndef METADATA_CAMERA_SOURCE
     OMX_ERRORTYPE err =
         requestedType == kMetadataBufferTypeANWBuffer
                 ? OMX_GetExtensionIndex(mHandle, nativeBufferName, &index)
                 : OMX_ErrorUnsupportedIndex;
+#else
+    OMX_ERRORTYPE err = OMX_GetExtensionIndex(mHandle, nativeBufferName, &index);
+#endif
     OMX_ERRORTYPE xerr = err;
     if (err == OMX_ErrorNone) {
         err = OMX_SetParameter(mHandle, index, &params);
         if (err == OMX_ErrorNone) {
             name = nativeBufferName; // set name for debugging
+#ifndef METADATA_CAMERA_SOURCE
             negotiatedType = requestedType;
+#else
+            negotiatedType = kMetadataBufferTypeANWBuffer;
+#endif
         }
     }
     if (err != OMX_ErrorNone) {
         err = OMX_GetExtensionIndex(mHandle, name, &index);
         xerr = err;
         if (err == OMX_ErrorNone) {
+#ifndef METADATA_CAMERA_SOURCE
             negotiatedType =
                 requestedType == kMetadataBufferTypeANWBuffer
                         ? kMetadataBufferTypeGrallocSource : requestedType;
+#else
+            negotiatedType = kMetadataBufferTypeGrallocSource;
+#endif
             err = OMX_SetParameter(mHandle, index, &params);
         }
     }
@@ -600,9 +616,14 @@
         }
         mMetadataType[portIndex] = negotiatedType;
     }
+#ifndef METADATA_CAMERA_SOURCE
     CLOG_CONFIG(storeMetaDataInBuffers, "%s:%u %srequested %s:%d negotiated %s:%d",
             portString(portIndex), portIndex, enable ? "" : "UN",
             asString(requestedType), requestedType, asString(negotiatedType), negotiatedType);
+#else
+    CLOG_CONFIG(storeMetaDataInBuffers, "%s:%u negotiated %s:%d",
+            portString(portIndex), portIndex, asString(negotiatedType), negotiatedType);
+#endif
 
     if (type != NULL) {
         *type = negotiatedType;
@@ -958,9 +979,11 @@
     }
 
     // Input buffers will hold meta-data (ANativeWindowBuffer references).
+#ifndef METADATA_CAMERA_SOURCE
     if (type != NULL) {
         *type = kMetadataBufferTypeANWBuffer;
     }
+#endif
     err = storeMetaDataInBuffers_l(portIndex, OMX_TRUE, type);
     if (err != OK) {
         return err;
diff -ur a/frameworks/av/media/libstagefright/tests/Android.mk b/frameworks/av/media/libstagefright/tests/Android.mk
--- a/frameworks/av/media/libstagefright/tests/Android.mk
+++ b/frameworks/av/media/libstagefright/tests/Android.mk
@@ -29,8 +29,12 @@
 LOCAL_C_INCLUDES := \
 	frameworks/av/media/libstagefright \
 	frameworks/av/media/libstagefright/include \
-	$(TOP)/frameworks/native/include/media/openmax \
-	$(TOP)/frameworks/native/include/media/hardware \
+	$(TOP)/frameworks/native/include/media/openmax
+
+ifneq ($(TARGET_HAS_LEGACY_CAMERA_HAL1), true)
+LOCAL_C_INCLUDES += \
+	$(TOP)/frameworks/native/include/media/hardware
+endif
 
 LOCAL_CFLAGS += -Werror -Wall
 LOCAL_CLANG := true
diff -ur a/frameworks/av/media/libstagefright/wifi-display/Android.mk b/frameworks/av/media/libstagefright/wifi-display/Android.mk
--- a/frameworks/av/media/libstagefright/wifi-display/Android.mk
+++ b/frameworks/av/media/libstagefright/wifi-display/Android.mk
@@ -17,9 +17,13 @@
 LOCAL_C_INCLUDES:= \
         $(TOP)/frameworks/av/media/libstagefright \
         $(TOP)/frameworks/native/include/media/openmax \
-        $(TOP)/frameworks/native/include/media/hardware \
         $(TOP)/frameworks/av/media/libstagefright/mpeg2ts \
 
+ifneq ($(TARGET_HAS_LEGACY_CAMERA_HAL1), true)
+LOCAL_C_INCLUDES+= \
+	$(TOP)/frameworks/native/include/media/hardware
+endif
+
 LOCAL_SHARED_LIBRARIES:= \
         libbinder                       \
         libcutils                       \
diff -ur a/frameworks/av/media/libstagefright/wifi-display/source/PlaybackSession.cpp b/frameworks/av/media/libstagefright/wifi-display/source/PlaybackSession.cpp
--- a/frameworks/av/media/libstagefright/wifi-display/source/PlaybackSession.cpp
+++ b/frameworks/av/media/libstagefright/wifi-display/source/PlaybackSession.cpp
@@ -948,10 +948,16 @@
 
     if (isVideo) {
         format->setString("mime", MEDIA_MIMETYPE_VIDEO_AVC);
+#ifndef METADATA_CAMERA_SOURCE
         format->setInt32(
                 "android._input-metadata-buffer-type", kMetadataBufferTypeANWBuffer);
         format->setInt32("android._store-metadata-in-buffers-output", (mHDCP != NULL)
                 && (mHDCP->getCaps() & HDCPModule::HDCP_CAPS_ENCRYPT_NATIVE));
+#else
+        format->setInt32("store-metadata-in-buffers", true);
+        format->setInt32("store-metadata-in-buffers-output", (mHDCP != NULL)
+                && (mHDCP->getCaps() & HDCPModule::HDCP_CAPS_ENCRYPT_NATIVE));
+#endif
         format->setInt32(
                 "color-format", OMX_COLOR_FormatAndroidOpaque);
         format->setInt32("profile-idc", profileIdc);
diff -ur a/frameworks/av/media/mediaserver/main_mediaserver.cpp b/frameworks/av/media/mediaserver/main_mediaserver.cpp
--- a/frameworks/av/media/mediaserver/main_mediaserver.cpp
+++ b/frameworks/av/media/mediaserver/main_mediaserver.cpp
@@ -28,6 +28,9 @@
 #include "IcuUtils.h"
 #include "MediaPlayerService.h"
 #include "ResourceManagerService.h"
+#ifdef METADATA_CAMERA_SOURCE
+#include "CameraService.h"
+#endif
 
 using namespace android;
 
@@ -41,6 +44,9 @@
     InitializeIcuOrDie();
     MediaPlayerService::instantiate();
     ResourceManagerService::instantiate();
+#ifdef METADATA_CAMERA_SOURCE
+    CameraService::instantiate();
+#endif
     registerExtensions();
     ProcessState::self()->startThreadPool();
     IPCThreadState::self()->joinThreadPool();
diff -ur a/frameworks/av/services/camera/libcameraservice/CameraService.cpp b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
--- a/frameworks/av/services/camera/libcameraservice/CameraService.cpp
+++ b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
@@ -831,7 +831,11 @@
 Status CameraService::initializeShimMetadata(int cameraId) {
     int uid = getCallingUid();
 
+#ifndef METADATA_CAMERA_SOURCE
     String16 internalPackageName("cameraserver");
+#else
+    String16 internalPackageName("media");
+#endif
     String8 id = String8::format("%d", cameraId);
     Status ret = Status::ok();
     sp<Client> tmp = nullptr;

